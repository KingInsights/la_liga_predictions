{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee46593-524b-4fe2-a401-a54c60480df1",
   "metadata": {},
   "source": [
    "## Web scraping Spanish La-Liga fixtures and results: Cleaning and analyzing the data to predict match outcomes using RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26626a2e-f741-44ce-a81f-21af6679104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Dependencies **\n",
    "\n",
    "# Importing necessary libraries for web scraping, data manipulation, and machine learning\n",
    "\n",
    "import requests  # To handle HTTP requests to fetch web page content\n",
    "from bs4 import BeautifulSoup  # To parse HTML and extract data from web pages\n",
    "import pandas as pd  # For data manipulation and analysis, especially for reading HTML tables and managing dataframes\n",
    "from io import StringIO  # To treat strings as file-like objects, useful for reading HTML content with pandas\n",
    "import time  # To handle time-related tasks, such as pauses between requests to avoid overloading servers\n",
    "\n",
    "# Importing necessary libraries for machine learning and model evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier  # To build a random forest model for classification tasks\n",
    "from sklearn.metrics import accuracy_score  # To calculate the accuracy of the classification model\n",
    "from sklearn.metrics import classification_report  # To generate a detailed report of classification metrics (precision, recall, f1-score, etc.)\n",
    "\n",
    "\n",
    "# Importing necessary libraries for data visualization\n",
    "import matplotlib.pyplot as plt  # To create static, animated, and interactive visualizations in Python\n",
    "import seaborn as sns  # To create attractive and informative statistical graphics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be92768-88c9-4f87-9bdc-81bb7e3209c2",
   "metadata": {},
   "source": [
    "## **Stage 1: Scraping the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d6131-22d7-4d2d-a5a8-50c15febad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the La-Liga statistics page to scrape\n",
    "# url = \"https://fbref.com/en/comps/12/La-Liga-Stats\"\n",
    "\n",
    "url = \"https://fbref.com/en/comps/12/2023-2024/2023-2024-La-Liga-Stats\"\n",
    "\n",
    "# Send a GET request to the main page to retrieve the HTML content\n",
    "data_1 = requests.get(url)\n",
    "\n",
    "data_1  # This will show the status code, e.g., <Response [200]> if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fb73d-c0f4-4e1d-8429-8a731e0f58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of BeautifulSoup with the HTML content from the GET request\n",
    "soup = BeautifulSoup(data_1.text, \"html.parser\")\n",
    "\n",
    "# Display the parsed HTML content (optional, for debugging)\n",
    "# print(soup.prettify()[:1000])  # Print the first 1000 characters of the parsed HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b5c73-267a-4f47-9a8d-9227cc34ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the second 'table.stats_table' element from the HTML\n",
    "league_table = soup.select('table.stats_table')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f22970-dcdb-4675-87eb-63d78a76c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all 'a' (anchor) tags within the league table\n",
    "links = league_table.find_all('a')\n",
    "\n",
    "# Extract the href attributes from the links \n",
    "links = [l.get(\"href\") for l in links]\n",
    "\n",
    "# Filter to include only those containing '/squads/'\n",
    "links = [l for l in links if '/squads/' in l]\n",
    "\n",
    "# Print the first few links directly\n",
    "for link in links[:3]:  # Adjust the number of links you want to print\n",
    "    print(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973fef7-d284-4648-bf36-6ca77bd6cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full URLs for each team by appending the base URL to each link\n",
    "team_urls = [f\"https://fbref.com{l}\" for l in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05826731-47ea-46b1-a55e-c969fd78bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of full URLs for each team created by appending the base URL to each filtered link\n",
    "team_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62ff13-ff9f-4822-91c5-77693d752078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one team URL for example purposes\n",
    "team_url = team_urls[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d694c8e-9b3e-4b34-8267-a4b61d9f1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the selected team URL\n",
    "print(team_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c317ff4-46f6-4f9d-a10e-b62f71df3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the team page for just Barcelona using the previously selected team URL\n",
    "data_2 = requests.get(team_url)\n",
    "\n",
    "# Display the response object for the Barcelona team page (this will show the status of the request, optional)\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7862ea-6c9d-4082-b0c9-2133ab429441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML content with BeautifulSoup\n",
    "# Useful for investigating the structure of the HTML or extracting additional data if needed\n",
    "soup_2 = BeautifulSoup(data_2.text, \"html.parser\")\n",
    "\n",
    "# Find all tables in the parsed HTML\n",
    "tables = soup_2.find_all('table')\n",
    "\n",
    "# Print the captions of the tables to identify the correct one (\"Scores & Fixtures\")\n",
    "for idx, table in enumerate(tables):\n",
    "    caption = table.find('caption')\n",
    "    if caption:\n",
    "        print(f\"Table {idx}: {caption.text}\")  # Print the index and caption text to identify the tables\n",
    "    else:\n",
    "        print(f\"Table {idx} has no caption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5c69d-770e-45e4-967f-36531ad85f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to read in the tables \n",
    "\n",
    "# Wrap the HTML content of the team page (data_2.text) with the StringIO function \n",
    "# This allows the HTML data to be read by pandas as if it were a file\n",
    "html_data = StringIO(data_2.text)\n",
    "\n",
    "# Use pandas to read the HTML data and find the table that matches \"Scores & Fixtures\"\n",
    "# This extracts the relevant table from the HTML content\n",
    "matches = pd.read_html(html_data, match=\"Scores & Fixtures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a41f0-c811-41b1-a1b0-674aef383554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the extracted table for \"Scores & Fixtures\" for the team\n",
    "# [0] is used here to select the first table from a list of tables (even if there is only 1)\n",
    "matches[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20e6b5-0dff-4afb-ab47-093e545cad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script scrapes the fixtures and results from multiple team URLs,\n",
    "# processes the data, and combines it into a single CSV file. The script includes\n",
    "# error handling and retries with exponential backoff for failed requests.\n",
    "\n",
    "all_matches = []\n",
    "skipped_urls = []\n",
    "\n",
    "# Function to send a GET request with retries and exponential backoff\n",
    "def get(url, max_retries=5, max_wait_time=60):\n",
    "    wait_time = 1  # Initial wait time in seconds\n",
    "    for i in range(max_retries):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        elif response.status_code == 429:\n",
    "            retry_after = int(response.headers.get(\"Retry-After\", wait_time))\n",
    "            print(f\"Rate limit exceeded. Retrying after {retry_after} seconds.\")\n",
    "            if retry_after > max_wait_time:\n",
    "                print(f\"Retry after {retry_after} seconds is too long. Skipping {url}.\")\n",
    "                return None\n",
    "            time.sleep(retry_after)\n",
    "            wait_time = min(60, wait_time * 2)  # Exponential backoff\n",
    "        else:\n",
    "            print(f\"Failed to get page, status code: {response.status_code}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Loop through each team URL to scrape data\n",
    "for team_url in team_urls:\n",
    "    # Extract team name from the URL\n",
    "    team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "    response = get(team_url)\n",
    "\n",
    "    if not response:\n",
    "        print(f\"Skipping {team_name} due to repeated get failures.\")\n",
    "        skipped_urls.append(team_url)\n",
    "        continue\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Print the title to confirm it's the right page\n",
    "    print(soup.title.string)\n",
    "\n",
    "    # Find all tables with the class 'stats_table'\n",
    "    tables = soup.find_all('table', {'class': 'stats_table'})\n",
    "    print(f\"Found {len(tables)} tables on {team_name} page\")\n",
    "\n",
    "\n",
    "    # Ensure that the matches variable is not empty, find caption in table make sure it contains 'scores & fixtures' \n",
    "    # then use pandas read_html function to assign the table to matches after it has been converted to string and an \n",
    "    # object, if matches empty then continue\n",
    "    matches = None\n",
    "    for idx, table in enumerate(tables):\n",
    "        caption = table.find('caption')\n",
    "        if caption and \"Scores & Fixtures\" in caption.text:\n",
    "            print(f\"Found 'Scores & Fixtures' table at index {idx}\")\n",
    "            matches = pd.read_html(StringIO(str(table)))[0]\n",
    "            break\n",
    "\n",
    "    if matches is None:\n",
    "        print(f\"Did not find 'Scores & Fixtures' table for {team_name}\")\n",
    "        continue\n",
    "\n",
    "    # Assuming 'matches' contains the required table, display the first few rows\n",
    "    print(matches.head())\n",
    "\n",
    "    try:\n",
    "        # Filter the matches for La Liga competition and add season and team name columns\n",
    "        matches = matches[matches[\"Comp\"] == \"La Liga\"]\n",
    "        matches[\"Season\"] = '2023-2024'\n",
    "        matches[\"Team\"] = team_name\n",
    "        all_matches.append(matches)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing matches for {team_name}: {e}\")\n",
    "\n",
    "   # Add a delay between requests to avoid rate limiting\n",
    "    print(\"Waiting for 5 seconds before the next request...\")  # Added print statement\n",
    "    time.sleep(5)  # Delay of 10 seconds between each loop iteration, as was having issues scraping data. \n",
    "\n",
    "# Combine all dataframes into one\n",
    "if all_matches:\n",
    "    all_matches_la_liga_2324 = pd.concat(all_matches, ignore_index=True)\n",
    "    # Save the dataframe to a CSV file\n",
    "    all_matches_la_liga_2324.to_csv('all_matches_la_liga_2324.csv', index=False)\n",
    "    print(\"Data saved to all_matches_la_liga_2324.csv\")\n",
    "else:\n",
    "    print(\"No data collected\")\n",
    "\n",
    "# Log the skipped URLs\n",
    "if skipped_urls:\n",
    "    print(\"The following URLs were skipped due to rate limits or other issues:\")\n",
    "    for url in skipped_urls:\n",
    "        print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319df5e-27b3-4307-98fc-5305f6ba09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data has been collected and saved previously, so there is no need to scrape it again for this project.\n",
    "# We will load the data from the CSV file into a new DataFrame and work with that.\n",
    "la_liga_2324 = pd.read_csv('all_matches_la_liga_2324.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5484e77-eb58-47b3-bbbc-5ed4a1d1c085",
   "metadata": {},
   "source": [
    "## **Stage 2: Data Integrity and Preparing for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd88a29-980d-4c90-a72c-2dd104a3f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the first few rows of our DataFrame to understand its structure and content.\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f2169-6740-45e6-b76a-50ccc244b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at rearranging the columns, and maybe drop some columns if they are not needed\n",
    "# Get the list of current columns in the DataFrame\n",
    "current_columns = la_liga_2324.columns.tolist()\n",
    "\n",
    "# Display the list of current columns\n",
    "current_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747de634-9a71-4a8a-aadc-a3b4a99db555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out 'Match Report' and 'Notes' columns and define the new order of columns\n",
    "new_order = [\n",
    "    'Comp',\n",
    "    'Season',\n",
    "    'Round',\n",
    "    'Date',\n",
    "    'Time',\n",
    "    'Day',\n",
    "    'Team',\n",
    "    'Opponent',\n",
    "    'Venue',\n",
    "    'Result',\n",
    "    'GF',\n",
    "    'GA',\n",
    "    'Poss',\n",
    "    'Attendance',\n",
    "    'Captain',\n",
    "    'Formation',\n",
    "    'Referee'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c8134-dbbd-4ba0-91f5-4c1720cbd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new column order to the DataFrame\n",
    "la_liga_2324 = la_liga_2324[new_order]\n",
    "\n",
    "# Display the DataFrame with the new column order\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe6f2d-3283-4bce-9582-3df4c6d1c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like to work with most data in lowercase, so let's convert the column titles to lowercase\n",
    "la_liga_2324.columns = la_liga_2324.columns.str.lower()\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the column title changes\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87530793-1178-4c82-b06b-30236310b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that each team has played 38 games\n",
    "\n",
    "# Count the number of instances (games) for each team in the 'team' column\n",
    "team_counts = la_liga_2324['team'].value_counts()\n",
    "\n",
    "# Display the results to verify that each team has played 38 games\n",
    "print(\"Number of instances of each team:\")\n",
    "print(team_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bc96c-21ec-4fbb-86b6-cd57cea43f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - check the right number of rows\n",
    "# There are 20 teams \n",
    "# However, each team does not play itself, so there are 2 fewer games per team\n",
    "# Therefore, the total games should be 20 * 38\n",
    "\n",
    "total_games = 20 * 38 \n",
    "\n",
    "# Print the total games expected and the actual number of rows in the DataFrame\n",
    "print(f\"Total games played in La Liga = {total_games} versus the games (rows) in the DataFrame = {la_liga_2324.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0db456-f6f9-4e09-b397-939818430059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checking to ensure the matches played per match week (round) are all the same.\n",
    "\n",
    "# Count the number of entries for each round\n",
    "round_counts = la_liga_2324[\"round\"].value_counts()\n",
    "\n",
    "# Sort the round counts by extracting the numerical part of the matchweek\n",
    "round_counts = round_counts.sort_index(key=lambda x: x.str.extract(r'(\\d+)').astype(int)[0])\n",
    "\n",
    "\n",
    "# Initialize a flag to check if all rounds have 20 entries\n",
    "all_rounds_have_20 = True\n",
    "\n",
    "# Iterate through the round counts to verify each round has 20 matches\n",
    "for round_number, count in round_counts.items():\n",
    "    if count != 20:\n",
    "        print(f\"Issue found: Round {round_number} has {count} entries instead of 20.\")\n",
    "        all_rounds_have_20 = False\n",
    "\n",
    "# Check if all rounds have 20 entries and print the result\n",
    "if all_rounds_have_20:\n",
    "    print(\"All rounds have 20 entries.\")\n",
    "else:\n",
    "    print(\"Not all rounds have 20 entries.\")\n",
    "\n",
    "# Display the round counts for reference\n",
    "print(\"\\nRound counts:\")\n",
    "print(round_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a435c3-48c9-4bb9-a108-664fabbfb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of the DataFrame columns to understand the structure of the data\n",
    "print(la_liga_2324.dtypes)  # Display the data types of each column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbc381-2b67-4ee4-8ac0-7e406aa9c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert necessary columns to numerical formats as needed for ML algorithms\n",
    "# This part of the code would include steps like encoding categorical variables, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f32a0e-bff9-477c-a391-6a1252fafd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format to ensure it is in the correct format for analysis\n",
    "la_liga_2324[\"date\"] = pd.to_datetime(la_liga_2324[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0231a76-3ea1-4206-af95-818373283fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick confirmation of the data types of each column in the DataFrame\n",
    "la_liga_2324.dtypes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d5a2a-f842-48bc-9af6-6d79f47e1e3d",
   "metadata": {},
   "source": [
    "## Converting 'venue' Column to Numerical Codes for Machine Learning\n",
    "\n",
    "Convert the 'venue' column to categorical type and then to numerical codes for machine learning. The venue code is important for football match predictions for several reasons:\n",
    "\n",
    "## Importance of Venue Code:\n",
    "\n",
    "1. **Home Advantage**: Teams playing at their home venue often have a significant advantage.\n",
    "2. **Travel Fatigue**: Away teams usually experience travel fatigue, affecting their performance.\n",
    "3. **Crowd Support**: Local fans can boost the home team's morale and put pressure on the visiting team.\n",
    "4. **Pitch Conditions**: Teams are familiar with their home pitch conditions, providing a tactical advantage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34493ec-4ac3-486b-a1dc-940bf82d46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_liga_2324[\"venue_code\"] = la_liga_2324[\"venue\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Display the DataFrame to verify that the 'venue_code' column has been added correctly\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914e5c3-a3b3-4489-8c42-b83d1b7fd3d6",
   "metadata": {},
   "source": [
    "## Converting 'opponent' Column to Numerical Codes for Machine Learning\n",
    "\n",
    "Convert the 'opponent' column to categorical type and then to numerical codes for machine learning. Using 'opp_code' helps the model learn not only the specific relationship between the two teams but also broader patterns, strengths, and performance trends across multiple matches and contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd2623-4086-4b38-8359-de92898c8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_liga_2324[\"opp_code\"] = la_liga_2324[\"opponent\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Display the DataFrame to verify that the 'opp_code' column has been added correctly\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6d10e-bb03-4d84-9647-b59d317a49ec",
   "metadata": {},
   "source": [
    "### Steps to Enhance Predictions with Match Hour Data\n",
    "\n",
    "1. **Extract Hour from 'Time' Column:**\n",
    "   - Extract the hour from the 'time' column by removing everything after the colon.\n",
    "   - Convert the extracted hour to an integer type for machine learning.\n",
    "\n",
    "2. **Why Hour of the Match is a Good Predictor:**\n",
    "   - **Player Performance:** Players may perform differently at various times of the day due to factors like energy levels and routines.\n",
    "   - **Weather Conditions:** Weather can vary throughout the day, potentially impacting match conditions and player performance.\n",
    "   - **Audience and Atmosphere:** Matches held at prime times may have larger audiences and more intense atmospheres, influencing team performance.\n",
    "   - **Travel and Preparation:** The time of day can affect teams' travel schedules and preparation routines, impacting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5016c-37c7-466d-a7a5-000d7879ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with a default hour, e.g., '00:00' (midnight)\n",
    "la_liga_2324[\"time\"].fillna(\"00:00\", inplace=True)\n",
    "\n",
    "\n",
    "la_liga_2324[\"hour\"] = la_liga_2324[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(\"int\")\n",
    "\n",
    "# Display the DataFrame to verify that the 'hour' column has been added correctly\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837d7d9-8a27-4b88-b4c4-e48c8ab96487",
   "metadata": {},
   "source": [
    "### Steps to Enhance Predictions with Day of the Week Data\r\n",
    "\r\n",
    "1. **Convert Date to Day of the Week:**\r\n",
    "   - Convert the 'date' column to the day of the week and store it in a new 'day_code' column.\r\n",
    "   - Convert the 'day of the week' column to a suitable format for machine learning.\r\n",
    "\r\n",
    "2. **Why Day of the Week is a Good Predictor:**\r\n",
    "   - **Player Recovery:** Players may have different levels of rest and recovery depending on the match schedule and training routines.\r\n",
    "   - **Team Strategy:** Teams might adopt different strategies based on the day, such as rotation policies for midweek vs. weekend games.\r\n",
    "   - **Audience and Atmosphere:** Weekend games may attract larger crowds and more vibrant atmospheres, influencing player performance.\r\n",
    "   - **Match Importance:** Certain days may be associated with more significant matches (e.g., Sunday league fixtures, midweek cup games).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68cef9-b766-43df-b91d-e0f8f7b6790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The day of the week is represented as an integer where Monday is 0 and Sunday is 6\n",
    "la_liga_2324[\"day_code\"] = la_liga_2324[\"date\"].dt.dayofweek\n",
    "\n",
    "# Display the DataFrame to verify that the 'day_code' column has been added correctly\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e61cd-cbea-4093-b538-6ff1667ef010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the 'result' column to numerical values for machine learning\n",
    "# 'D' (Draw) is mapped to 0, 'W' (Win) is mapped to 1, and 'L' (Loss) is mapped to 2\n",
    "la_liga_2324['target'] = la_liga_2324['result'].apply(lambda x: 0 if x == 'D' else (1 if x == 'W' else 2))\n",
    "\n",
    "# Display the DataFrame to verify that the 'target' column has been added correctly\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad04cf7-5b43-46d0-9252-0f3dfa65a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick checks now to save any issues later\n",
    "# Check the data types of the DataFrame columns\n",
    "\n",
    "print(la_liga_2324.dtypes)  # Display the data types to ensure all columns are correctly formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ee998-376c-4158-b53b-9d7fa95b57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready for some machine learning, but let's save the work we've done so far.\n",
    "# This way, we can simply load the saved CSV into a DataFrame from here onward.\n",
    "\n",
    "# Save the current DataFrame to a CSV file\n",
    "la_liga_2324.to_csv('la_liga_2324.csv', index=False)\n",
    "\n",
    "\n",
    "# DataFrame after saving to confirm everything is in lowercase and predictors are added\n",
    "la_liga_2324.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f9453-85c5-4e8f-b332-9b32660b32b0",
   "metadata": {},
   "source": [
    "## Loading the Prepared DataFrame from a Saved CSV File\n",
    "\n",
    "Instead of recreating the DataFrame with all the previous actions, you can start from here and simply load the saved CSV file. This allows you to skip the data preparation steps if they have already been done, saving time and ensuring consistency. You can either continue with the code from here or load the prepared DataFrame from the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbadf0f-2629-4477-8be8-de154f84048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_liga_2324 = pd.read_csv('la_liga_2324.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667647fc-4b10-4447-ad4f-dda6aac3d22c",
   "metadata": {},
   "source": [
    "## **Stage 3: Machine Learning with RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a35cc9-87cd-4ca3-a35f-f8fc2a4b2c19",
   "metadata": {},
   "source": [
    "## RandomForestClassifier Overview\n",
    "\n",
    "RandomForestClassifier is an ensemble learning method that constructs multiple decision trees during training.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "Decision trees are models that split the data into subsets based on feature values to make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d43cd1-53e6-449a-9b63-a12ac9ee03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ff869-850b-4106-8be7-cc107cacb5d7",
   "metadata": {},
   "source": [
    "## Initializing a RandomForestClassifier with Specified Parameters\n",
    "\n",
    "- **n_estimators**: Controls the number of decision trees in the forest (here set to 50).\n",
    "- **min_samples_split**: Specifies the minimum number of samples required to split an internal node (set to 10).\n",
    "- **random_state**: Sets the seed for random number generation to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280afca-d65c-40d0-82c1-e09e7e4798f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf4928-4ed7-47df-b544-05adb86888da",
   "metadata": {},
   "source": [
    "## Decide on the Predictors for the Model - Starting Very Basic\n",
    "\n",
    "## Initial Considerations\n",
    "\n",
    "- **Initial Predictors**: Included 'gf' (goals for) and 'ga' (goals against).\n",
    "- **Issue**: These are results and should not be used as predictors.\n",
    "- **Action**: Remove 'gf' and 'ga' from the predictors list.\n",
    "\n",
    "## Defining the Predictors for the Model\n",
    "\n",
    "- The predictors should be variables that influence the outcomes but are not direct results.\n",
    "- Carefully select features that are relevant for making accurate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c20889-4140-432c-b131-ff8607c5b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_v1 = [\"venue_code\", \"opp_code\", \"hour\", \"day_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad203f-b54d-4710-aa72-be2a1f1afc21",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets\n",
    "\n",
    "Since this is time series data, we need to ensure that the test data comes after the train data. We can't use future data to predict the past, as the past is already known (it's history). We will split the data 75/25 for training/testing.\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "- **Time Series Consideration**: Ensure that the test data comes after the train data.\n",
    "- **Historical Data**: Future data cannot be used to predict past events.\n",
    "- **Split Ratio**: The data will be split into 75% for training and 25% for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e89e9d-2263-4c04-8d75-4d9c82897144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the start and end dates of our data to ensure the split is in chronological order.\n",
    "# Sorting the DataFrame by 'date' ensures that the data is ordered chronologically.\n",
    "# Resetting the index ensures the DataFrame index reflects the new chronological order.\n",
    "\n",
    "la_liga_2324 = la_liga_2324.sort_values(by='date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5564a5-fd62-45ea-9a6d-e161d4693a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the start and end date of the dataset\n",
    "season_start_date = la_liga_2324['date'].min()\n",
    "season_end_date = la_liga_2324['date'].max()\n",
    "\n",
    "# Display the start and end date of the dataset\n",
    "print(f\"Start Date: {season_start_date}\")\n",
    "print(f\"End Date: {season_end_date}\")\n",
    "\n",
    "# Filter the DataFrame to include data only within the specified date range\n",
    "season_data = la_liga_2324[(la_liga_2324['date'] >= season_start_date) & (la_liga_2324['date'] <= season_end_date)]\n",
    "\n",
    "# Calculate the index for the 75% training and 25% testing split\n",
    "split_index = int(len(season_data) * 0.75)\n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "train = season_data.iloc[:split_index]\n",
    "test = season_data.iloc[split_index:]\n",
    "\n",
    "# Define the predictors and target variables for training and testing\n",
    "X_train = train[predictors_v1]\n",
    "y_train = train[\"target\"]\n",
    "X_test = test[predictors_v1]\n",
    "y_test = test[\"target\"]\n",
    "\n",
    "# Fit the RandomForestClassifier model with the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test data\n",
    "preds_v1 = rf.predict(X_test)\n",
    "\n",
    "# accuracy_score is a function provided by the sklearn.metrics module in scikit-learn, a popular machine learning library \n",
    "# in Python. It is used to evaluate the accuracy of classification models.\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Calculate the accuracy score by comparing the predicted values with the actual target values\n",
    "acc_v1 = accuracy_score(test[\"target\"], preds_v1)\n",
    "\n",
    "# Print the predictions, accuracy score, and length of predictions\n",
    "print(preds_v1)\n",
    "print(f\"Accuracy: {acc_v1:.4f}\")\n",
    "print(f\"Length of predictions: {len(preds_v1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b73758-2a93-4de7-8abd-c0703df41ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual vs. predicted values\n",
    "combined_v1 = pd.DataFrame(dict(actual=test[\"target\"], prediction=preds_v1))\n",
    "\n",
    "# Create a cross-tabulation (crosstab) of actual vs. predicted values\n",
    "# Cross-tabulation helps us understand the frequency distribution of predictions\n",
    "# It shows how many predictions fall into each combination of actual and predicted values\n",
    "cross_tabulation = pd.crosstab(index=combined_v1['actual'], columns=combined_v1['prediction'])\n",
    "\n",
    "# Display the cross-tabulation\n",
    "cross_tabulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044ab65-99d4-415f-8fc7-0a58b055a8ae",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "The classification report provides a detailed breakdown of how well the machine learning model performs across different classes (categories), including precision (accuracy of positive predictions), recall (sensitivity), and F1-score (harmonic mean of precision and recall). These metrics are crucial for understanding the model's predictive accuracy and its ability to correctly identify each class, offering valuable insights into its overall performance.\n",
    "\n",
    "## Key Metrics:\n",
    "\n",
    "- **Precision**: Measures the accuracy of positive predictions, focusing on how many selected items are relevant.\n",
    "\n",
    "- **Recall (Sensitivity)**: Measures the ability of the model to find all positive instances, focusing on how many relevant items are selected.\n",
    "\n",
    "- **F1-score**: Combines precision and recall into a single metric, providing a balanced measure useful for comparing models with varying precision and recall performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183d623-ffd3-4764-a4be-ca72997785f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Extract actual and predicted values from the combined DataFrame\n",
    "actual = combined_v1['actual']\n",
    "prediction = combined_v1['prediction']\n",
    "\n",
    "# Generate the classification report\n",
    "# Classification report provides metrics like precision, recall, and F1-score for each class.\n",
    "report_v1 = classification_report(actual, prediction, target_names=['Class 0', 'Class 1', 'Class 2'])\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_v1)\n",
    "\n",
    "# Length of preds is the number of predictions made\n",
    "length_preds = len(preds_v1)\n",
    "print(\"Length of preds:\", length_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cada115-280d-4957-9fbb-929b00c5a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Parse the classification report string into a DataFrame\n",
    "report_df = pd.read_csv(StringIO(report_v1), delim_whitespace=True)\n",
    "\n",
    "# Correcting the index to properly filter out 'accuracy', 'macro avg', and 'weighted avg'\n",
    "report_df.index = ['Class 0', 'Class 1', 'Class 2', 'accuracy', 'macro avg', 'weighted avg']\n",
    "\n",
    "# Extracting precision, recall, and F1-score for each class\n",
    "metrics_df = report_df.loc[['Class 0', 'Class 1', 'Class 2'], ['precision', 'recall', 'f1-score']]\n",
    "\n",
    "# Reset index for better plotting with seaborn\n",
    "metrics_df = metrics_df.reset_index().rename(columns={'index': 'Class'})\n",
    "\n",
    "# Melt the DataFrame to long format for easier plotting with seaborn\n",
    "metrics_melted = metrics_df.melt(id_vars='Class', var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plotting the metrics using seaborn with yellow, orange, and purple palette\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=metrics_melted, x='Class', y='Score', hue='Metric', palette=['gold', 'orange', 'limegreen'])\n",
    "\n",
    "plt.gca().set_xticks(range(len(['Draw', 'Home Win', 'Away Win'])))\n",
    "plt.gca().set_xticklabels(['Draw', 'Home Win', 'Away Win'])\n",
    "\n",
    "\n",
    "\n",
    "# Enhancing the plot aesthetics\n",
    "plt.title('Classification Report Metrics', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.ylim(0, 1)  # Setting y-axis limit for better comparison\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')  # Adding legend outside the plot\n",
    "plt.xticks(rotation=0)  # Ensuring class labels are readable\n",
    "plt.grid(True, linestyle='--', alpha=0.7)  # Adding grid lines for clarity\n",
    "\n",
    "# Displaying the plot\n",
    "plt.tight_layout()  # Ensuring all elements fit within the figure area\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06541ab3-8be7-4745-86e4-ea32e608d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display test data, true targets, predictions, and result of predictions\n",
    "la_liga_2324_results = test.copy()\n",
    "\n",
    "# Add a column for predictions made by the Random Forest Classifier\n",
    "la_liga_2324_results['pred_rfc'] = preds_v1\n",
    "\n",
    "# Create a column to indicate the outcome of each prediction\n",
    "la_liga_2324_results['result_rfc'] = la_liga_2324_results.apply(lambda row: 'success' if row['target'] == row['pred_rfc'] else 'failure', axis=1)\n",
    "\n",
    "# Select and rearrange columns as desired\n",
    "la_liga_2324_results = la_liga_2324_results[['date', 'team', 'opponent', 'target', 'pred_rfc', 'result_rfc']]\n",
    "\n",
    "# Display the first few rows of the results DataFrame\n",
    "la_liga_2324_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cc8ee-d86c-44ad-831d-3f48daeeec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results DataFrame to a CSV file if you wish to inspect further\n",
    "la_liga_2324_results.to_csv('la_liga_2324_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41bf08-37a4-43b6-a1ca-cc831418a47f",
   "metadata": {},
   "source": [
    "## **Stage 4: Adding Additional Data/Features for ML to Improve Predictions**\n",
    "\n",
    "## Enhancing Predictive Power by Incorporating New Features Specific to La Liga Matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c318e-bdc7-4f2b-85ec-81bd93f684f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy with increment ver of la_liga_2324 to preserve its integrity before adding new features.\n",
    "# This ensures that any modifications do not affect the original DataFrame.\n",
    "la_liga_2324_v1 = la_liga_2324.copy()\n",
    "la_liga_2324_v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4462a3-4fb7-41e5-87e7-fa89717f612a",
   "metadata": {},
   "source": [
    "## Calculate Rolling Averages for Goals For, Against, and Possession\n",
    "\n",
    "Rolling averages help capture trends over time, smoothing out short-term fluctuations. This is useful in machine learning models as it highlights the form of a team over recent matches, providing a better indication of future performance compared to individual match results.\n",
    "\n",
    "## Key Points:\n",
    "\n",
    "- **Goals For**: Calculate the rolling average of goals scored by a team over a specified number of matches.\n",
    "- **Goals Against**: Calculate the rolling average of goals conceded by a team over a specified number of matches.\n",
    "- **Possession**: Calculate the rolling average of possession percentage (an indicator of passing accuracy and efficiency) over a specified number of matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3084-6571-435d-95ed-c519fcd87588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Before calculating rolling averages, group the matches by team to perform calculations per team.\n",
    "grouped_matches = la_liga_2324_v1.groupby(\"team\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a040ef7-777a-4fef-a168-7ff880bba122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display the matches data for the team \"Barcelona\" from the grouped DataFrame.\n",
    "group = grouped_matches.get_group(\"Barcelona\")\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d897-f6e8-43de-b54e-eeaf2428ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_averages(group, cols, new_cols):\n",
    "    \"\"\"\n",
    "    Compute rolling averages for specified columns within each group (by team).\n",
    "\n",
    "    Parameters:\n",
    "    - group: DataFrame group for a specific team.\n",
    "    - cols: List of columns to compute rolling averages for.\n",
    "    - new_cols: List of new column names to assign to the rolling average results.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with calculated rolling averages added as new columns.\n",
    "    \"\"\"\n",
    "    group = group.sort_values(\"date\")  # Sort the group data by 'date' for chronological order\n",
    "    rolling_stats = group[cols].rolling(window=3, closed='left').mean()  # Calculate rolling averages for selected columns\n",
    "    group[new_cols] = rolling_stats  # Assign calculated rolling averages to new columns in the DataFrame\n",
    "    group = group.dropna(subset=new_cols)  # Drop rows with NaN values in the newly created columns\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057593d-2651-48bd-bc7c-101e636b94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for which rolling averages will be calculated\n",
    "cols = [\"gf\", \"ga\", \"poss\"]\n",
    "\n",
    "# Create new column names with '_rolling' suffix using list comprehension and f-string\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "\n",
    "# Display the new column names\n",
    "new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce922f8-bae1-4a42-8bfe-1a9d1dad2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the rolling_averages function to calculate rolling averages for selected columns\n",
    "# Assign the results to new columns with '_rolling' suffix\n",
    "group1 = rolling_averages(group, cols, new_cols)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame for selected team\n",
    "group1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea43959-ec1b-4ba9-a2af-f0f56ece50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the rolling_averages function to each team's data in la_liga_2324_v1 DataFrame\n",
    "# This function calculates rolling averages for specified columns (cols) and assigns the results to new columns (new_cols)\n",
    "la_liga_2324_v1 = la_liga_2324_v1.groupby(\"team\").apply(lambda x: rolling_averages(x, cols, new_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76535d00-1b3d-4f4f-b5db-8a2fbf2e8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the extra index level ('team') if multiple levels exist\n",
    "la_liga_2324_v1 = la_liga_2324_v1.droplevel('team')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72faca2f-09ed-454c-9f52-137de634eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index to ensure unique values\n",
    "la_liga_2324_v1.index = range(la_liga_2324_v1.shape[0])\n",
    "\n",
    "# Note: The DataFrame now contains only 700 rows because the rolling average function \n",
    "# dropped the NA values from the first 3 games of each team. This is because we needed \n",
    "# at least 3 matches to calculate a 3-period rolling average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a364319-e3e6-495c-ae21-aa571acab558",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_liga_2324_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19aedc-8bd8-4db0-8967-9414ddcfd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_liga_2324_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cdaa6-ea80-4a5e-ad32-4dc3da60128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's use Random Forest to see if adding the additional features\n",
    "# (rolling averages) has improved the model's performance.\n",
    "\n",
    "# First, save the DataFrame with all the rolling averages to a CSV file.\n",
    "la_liga_2324_v1.to_csv('la_liga_2324_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9a370-3ec8-49bd-ac8f-52ed37e0ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame containing rolling averages from the CSV file to\n",
    "# df with incremented ver\n",
    "la_liga_2324_v1 = pd.read_csv('la_liga_2324_v1.csv')\n",
    "la_liga_2324_v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ca5fc-52e1-431b-b0ab-f51cace5cf0b",
   "metadata": {},
   "source": [
    "## Importing the RandomForestClassifier from the sklearn.ensemble module\n",
    "\n",
    "Random Forest is a versatile and widely used machine learning algorithm known for its robustness and high performance in various predictive tasks. It operates by constructing multiple decision trees during training and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "\n",
    "## Key Features:\n",
    "\n",
    "- **Ensemble Method**: Aggregates predictions from multiple decision trees to improve accuracy and reduce overfitting.\n",
    "- **Versatility**: Suitable for both classification and regression tasks.\n",
    "- **Robustness**: Less prone to overfitting compared to individual decision trees.\n",
    "- **Feature Importance**: Provides insights into which features are most influential for making predictions.\n",
    "\n",
    "Random Forest is effective for complex datasets and can handle large amounts of data with high dimensionality, making it a popular choice in various domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668094c-3872-4313-8ab1-b68ad35cde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eefdfa-fdd6-41e6-a2b5-d211e50483a7",
   "metadata": {},
   "source": [
    "## Initializing a RandomForestClassifier with Specified Parameters\n",
    "\n",
    "- **n_estimators**: Controls the number of decision trees in the forest (here set to 50).\n",
    "- **min_samples_split**: Specifies the minimum number of samples required to split an internal node (set to 10).\n",
    "- **random_state**: Sets the seed for random number generation to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f2be9-820f-4d8b-ab27-b0797deec2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983725e-e1e0-4a73-b565-cb1cdf43aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting predictors for the RandomForestClassifier model, including new rolling average features:\n",
    "predictors_v2 = [\"venue_code\", \"opp_code\", \"hour\", \"day_code\", 'gf_rolling', 'ga_rolling', 'poss_rolling']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b40eb-6ff9-495a-a046-9199afbee5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the start and end date of the DataFrame\n",
    "# Note that the dates are dynamic and will change as the DataFrame is filtered\n",
    "\n",
    "season_start_date = la_liga_2324_v1['date'].min()\n",
    "season_end_date = la_liga_2324_v1['date'].max()\n",
    "\n",
    "# Display the start and end date of the season\n",
    "print(f\"Start Date: {season_start_date}\")\n",
    "print(f\"End Date: {season_end_date}\")\n",
    "\n",
    "# Filter the DataFrame to include matches within the specified date range\n",
    "season_data = la_liga_2324_v1[(la_liga_2324_v1['date'] >= season_start_date) & (la_liga_2324_v1['date'] <= season_end_date)]\n",
    "\n",
    "# Calculate the index for the 75% split for training and testing data\n",
    "split_index = int(len(season_data) * 0.75)\n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "train = season_data.iloc[:split_index]\n",
    "test = season_data.iloc[split_index:]\n",
    "\n",
    "# Define predictors and target variables\n",
    "X_train = train[predictors_v2]\n",
    "y_train = train[\"target\"]\n",
    "X_test = test[predictors_v2]\n",
    "y_test = test[\"target\"]\n",
    "\n",
    "# Fit the RandomForestClassifier model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the trained model on the test data\n",
    "preds_v2 = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy score to evaluate the model performance\n",
    "acc_v2 = accuracy_score(test[\"target\"], preds_v2)\n",
    "\n",
    "# Print predictions and accuracy score\n",
    "print(preds_v2)\n",
    "print(f\"Accuracy Score: {acc_v2:.4f}\")\n",
    "\n",
    "# Display the length of predictions\n",
    "length_preds_v2 = len(preds_v2)\n",
    "print(\"Length of preds_v2:\", length_preds_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934b0cc-323f-4aae-84fd-7248a3e55497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to compare actual and predicted values\n",
    "combined_v2 = pd.DataFrame(dict(actual=test[\"target\"], prediction=preds_v2))\n",
    "\n",
    "# Generate a cross-tabulation to analyze the classification results\n",
    "cross_tab_v2 = pd.crosstab(index=combined_v2['actual'], columns=combined_v2['prediction'])\n",
    "cross_tab_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514c2d0-9ac6-4409-a906-e5f4e551d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report v2\n",
    "\n",
    "# Extract actual and predicted values from combined_v2 DataFrame\n",
    "actual_v2 = combined_v2['actual']\n",
    "prediction_v2 = combined_v2['prediction']\n",
    "\n",
    "# Generate the classification report with specified target names for clarity\n",
    "report_v2 = classification_report(actual_v2, prediction_v2, target_names=['Class 0', 'Class 1', 'Class 2'])\n",
    "\n",
    "# Print the classification report header\n",
    "print(\"\\nClassification Report:\")\n",
    "\n",
    "# Print the detailed classification report showing precision, recall, F1-score, and support for each class\n",
    "print(report_v2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a303cdd-8ec1-47db-af8f-5d9192d10522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "\n",
    "# report_v2 is the classification report string\n",
    "\n",
    "# Parse the string to a DataFrame\n",
    "report_df = pd.read_csv(StringIO(report_v2), delim_whitespace=True)\n",
    "\n",
    "# Correcting the index to properly filter out 'accuracy', 'macro avg', and 'weighted avg'\n",
    "report_df.index = ['Class 0', 'Class 1', 'Class 2', 'accuracy', 'macro avg', 'weighted avg']\n",
    "metrics_df = report_df.loc[['Class 0', 'Class 1', 'Class 2'], ['precision', 'recall', 'f1-score']]\n",
    "\n",
    "# Reset index for better plotting with seaborn\n",
    "metrics_df = metrics_df.reset_index().rename(columns={'index': 'Class'})\n",
    "\n",
    "# Melt the DataFrame for seaborn\n",
    "metrics_melted = metrics_df.melt(id_vars='Class', var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plot the metrics using seaborn with custom palette\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=metrics_melted, x='Class', y='Score', hue='Metric', palette=['gold', 'orange', 'limegreen'])\n",
    "\n",
    "plt.gca().set_xticks(range(len(['Draw', 'Home Win', 'Away Win'])))\n",
    "plt.gca().set_xticklabels(['Draw', 'Home Win', 'Away Win'])\n",
    "\n",
    "\n",
    "# Enhance the plot with titles, labels, and limits\n",
    "plt.title('Classification Report Metrics Enhanced Features', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624b0a6-72d1-4b2c-ad89-d0db9b02f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the 2 reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d1ff6-44d2-4ce4-9e16-1ccb16979be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "\n",
    "# Assuming report_v1 and report_v2 are your classification report strings\n",
    "\n",
    "# Parse the strings to DataFrames\n",
    "report_df_v1 = pd.read_csv(StringIO(report_v1), delim_whitespace=True)\n",
    "report_df_v2 = pd.read_csv(StringIO(report_v2), delim_whitespace=True)\n",
    "\n",
    "# Correcting the index to properly filter out 'accuracy', 'macro avg', and 'weighted avg'\n",
    "report_df_v1.index = ['Class 0', 'Class 1', 'Class 2', 'accuracy', 'macro avg', 'weighted avg']\n",
    "report_df_v2.index = ['Class 0', 'Class 1', 'Class 2', 'accuracy', 'macro avg', 'weighted avg']\n",
    "\n",
    "# Keep only the class-specific rows\n",
    "metrics_df_v1 = report_df_v1.loc[['Class 0', 'Class 1', 'Class 2'], ['precision', 'recall', 'f1-score']]\n",
    "metrics_df_v2 = report_df_v2.loc[['Class 0', 'Class 1', 'Class 2'], ['precision', 'recall', 'f1-score']]\n",
    "\n",
    "# Add a column to distinguish between the reports\n",
    "metrics_df_v1['Report'] = 'Report 1'\n",
    "metrics_df_v2['Report'] = 'Report 2'\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_metrics_df = pd.concat([metrics_df_v1, metrics_df_v2])\n",
    "\n",
    "# Reset index for better plotting with seaborn\n",
    "combined_metrics_df = combined_metrics_df.reset_index().rename(columns={'index': 'Class'})\n",
    "\n",
    "# Melt the DataFrame for seaborn\n",
    "combined_metrics_melted = combined_metrics_df.melt(id_vars=['Class', 'Report'], var_name='Metric', value_name='Score')\n",
    "\n",
    "# Define a custom vibrant color palette (yellow, orange, and green)\n",
    "custom_palette = sns.color_palette([\"#FFD700\", \"#FFA07A\", \"#98FB98\", \"#FF6347\", \"#FF69B4\", \"#40E0D0\"])\n",
    "\n",
    "# Plot the metrics using seaborn with the custom color palette\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.set_palette(custom_palette)  # Set the custom color palette\n",
    "g = sns.catplot(data=combined_metrics_melted, x='Class', y='Score', hue='Metric', col='Report', kind='bar', height=5, aspect=1.2)\n",
    "\n",
    "plt.gca().set_xticks(range(len(['Draw', 'Home Win', 'Away Win'])))\n",
    "plt.gca().set_xticklabels(['Draw', 'Home Win', 'Away Win'])\n",
    "\n",
    "# Enhance the plot\n",
    "g.fig.subplots_adjust(top=0.9)  # Adjust the top to fit the title\n",
    "g.fig.suptitle('Comparison of Classification Report Metrics Standard v Enhanced Features', fontsize=16)\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_ylim(0, 1)  # y-axis shows the score values ranging from 0 to 1\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c25ae5-bfc9-4a1d-8b58-bd929862f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the hard work comes down to this:\n",
    "percent_increase = ((acc_v2 - acc_v1) / acc_v1) * 100\n",
    "print(f\"The original model accuracy score is {acc_v1:.4f}, while the model with enhanced features achieved {acc_v2:.4f}. This represents a {percent_increase:.2f}% increase from the original model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cd6a4-e968-40d5-974c-4f9340294b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The increase is only 5%, which might require a magnifying glass to see on a basic plot. Let's enhance \n",
    "# the visual for a clearer view. adjusting the y-axis scale effectively magnifies the difference in scores, \n",
    "#making the improvement more noticeable and impactful.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "models = ['Original Model', 'Enhanced Features Model']\n",
    "scores = [acc_v1, acc_v2]\n",
    "percent_increase = ((acc_v2 - acc_v1) / acc_v1) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, scores, color=['blue', 'orange'])\n",
    "plt.text(1, acc_v2 + 0.002, f'{acc_v2:.4f}', ha='center', va='bottom', fontsize=12, color='blue')\n",
    "plt.text(0, acc_v1 + 0.002, f'{acc_v1:.4f}', ha='center', va='bottom', fontsize=12, color='blue')\n",
    "\n",
    "# Highlight the increase with annotations\n",
    "plt.annotate(f'{percent_increase:.2f}% Increase', xy=(0.5, (acc_v1 + acc_v2) / 2), xytext=(0.5, (acc_v1 + acc_v2) / 2 + 0.005),\n",
    "             ha='center', va='bottom', fontsize=14, color='red',\n",
    "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Comparison of Model Accuracy Scores')\n",
    "plt.ylim(min(scores) - 0.01, max(scores) + 0.01)  # Adjusted y-axis limit to emphasize the difference\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064a458-2c14-47cd-9083-9f439fe15943",
   "metadata": {},
   "source": [
    "## Evaluating Football Match Outcome Predictions with a 44.6% Accuracy in a 3-Class Scenario (Win, Lose, Draw)\n",
    "\n",
    "## 1. Above Random Chance\n",
    "In a 3-class scenario (win, lose, draw), random guessing typically yields around 33% accuracy, assuming equal probability for each outcome. However, in football predictions, matches often have clear favorites, which means the actual baseline accuracy can be lower than 33%.\n",
    "\n",
    "## 2. Contextual Evaluation\n",
    "Predicting football matches involves complex factors, making 44.6% accuracy meaningful.\n",
    "\n",
    "## 3. Room for Improvement\n",
    "Despite promise, further enhancements in features or algorithms could boost accuracy.\n",
    "\n",
    "## 4. Benchmarking\n",
    "Comparing against other methods helps gauge competitiveness and identifies areas to improve.\n",
    "\n",
    "## Conclusion\n",
    "While 44.5% accuracy shows predictive capability, ongoing refinement is essential for reliable predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d077adb-0d76-4faa-be0d-73706e3a6987",
   "metadata": {},
   "source": [
    "## Improving the Model by Ensuring All Features Are Converted into Numerical Data for Effective Machine Learning Integration\n",
    "\n",
    "This includes transforming features such as shots on target, weather data (temperature, humidity, precipitation), cup game participation, player injuries/suspensions, home/away performance, and managerial changes into numerical formats.\n",
    "\n",
    "## Key Improvements:\n",
    "\n",
    "### 1. Incorporate Shots on Target Data\n",
    "Including statistics like shots on target per match could provide insights into offensive efficiency and potentially enhance predictive accuracy.\n",
    "\n",
    "### 2. Integrate Weather Data\n",
    "Weather conditions during matches can impact player performance and game outcomes. Incorporating weather data such as temperature, humidity, and precipitation may improve model robustness.\n",
    "\n",
    "### 3. Consider Cup Game Participation\n",
    "Teams participating in additional cup competitions may experience different levels of fatigue or prioritize differently, influencing their league performance. Including data on cup game participation could capture these dynamics.\n",
    "\n",
    "### 4. Account for Player Injuries and Suspensions\n",
    "Player availability due to injuries or suspensions significantly affects team performance. Tracking player injuries and suspensions and incorporating this data into the model could refine predictions.\n",
    "\n",
    "### 5. Evaluate Home and Away Performance\n",
    "Analyzing team performance differences between home and away matches can provide valuable insights. Incorporating home and away statistics may better capture the nuances of team dynamics.\n",
    "\n",
    "### 6. Include Managerial Changes\n",
    "Changes in coaching staff or managerial strategies can impact team performance. Monitoring managerial changes and their effects on team dynamics could contribute to more accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7f953-4c0a-4e2b-96b6-285ac6a8e35c",
   "metadata": {},
   "source": [
    "## Try Alternative Models\n",
    "\n",
    "## 1. Support Vector Machines (SVM)\n",
    "- **Explanation**: SVMs find the hyperplane that best separates classes in feature space. They use kernel functions for non-linear decision boundaries and are robust against overfitting, suitable for diverse datasets.\n",
    "\n",
    "## 2. Multinomial Logistic Regression\n",
    "- **Explanation**: Logistic Regression extends to multi-class problems via multinomial variants. It models class probabilities using the softmax function and predicts the class with the highest probability.\n",
    "\n",
    "## 3. Gradient Boosting Classifier (e.g., XGBoost, LightGBM)\n",
    "- **Explanation**: Gradient Boosting builds an ensemble of decision trees sequentially, where each corrects errors of its predecessor. Models like XGBoost and LightGBM are known for high accuracy and handling complex data interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f6e1e-a86d-40e3-a52c-534ff0dcbc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
